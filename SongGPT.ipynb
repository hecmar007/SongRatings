{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e81f51",
   "metadata": {},
   "source": [
    "Primer de tot, importem el text que volem utilitzar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d61050-41cf-4d81-816f-bd9445738c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('english_lyrics.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52dcc46c-3708-4eb4-a95b-a8c6e1f2aa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chorus: Opera Steve & Cam'ron]\n",
      "Killa Cam, Killa Cam, Cam\n",
      "Killa Cam, Killa Cam\n",
      "Killa Cam, Cam\n",
      "Killa Cam, Killa Cam, Cam\n",
      "Killa Killa Killa Cam\n",
      "Killa Cam, Cam, Killa (Killa!)\n",
      "Killa Cam, Killa Cam, Cam (Bases loaded)\n",
      "Killa Cam, Killa Cam (Uh-huh)\n",
      "Killa Cam, Cam (Santana on second, Jim on third)\n",
      "Killa Cam, Killa Cam, Cam (I'm at bat)\n",
      "Killa Killa Killa Cam\n",
      "Killa Cam, Cam, Killa (I'm 'bout to hit this shit out the world)\n",
      "Killa Cam (Ugh, Heatmakerz), Killa Cam, Cam\n",
      "Killa Cam, Killa Cam\n",
      "Killa Cam, Cam (Hahahaha)\n",
      "Killa Cam, Killa Cam, Cam\n",
      "Killa Killa Killa Cam\n",
      "Killa Cam, Cam, Killa (We  make this shit clap)\n",
      "Killa Cam, Killa Cam, Cam\n",
      "Killa Cam, Killa Cam\n",
      "Killa Cam, Cam\n",
      "Killa Cam, Killa Cam, Cam\n",
      "Killa Killa Killa Cam (Killa! Killa!)\n",
      "Killa Cam, Cam, Killa\n",
      "[Verse 1]\n",
      "With the goons I spar, stay in tune with ma (What up?)\n",
      "She like, \"Damn, this the realest since 'Kumbaya'\"\n",
      "Bomaye, Killa Cam, my Lord (My Lord)\n",
      "Still the man with the pan, scrilla, fam, on board\n",
      "Now bitches, they want to neuter me, nigga\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc6406cd-4405-49c3-9c7b-40643a0c0658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~ ¡´¿ÀÁÉÓÜàáâäçèéêëíîïñòóôöúüýāćēğīōœśūʼʿе​‎–—‘’“”•…′″⁠﻿\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39f0b3",
   "metadata": {},
   "source": [
    "Tokenització a nivell de caràcter, a cada caràcter si li assigna un número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e8cd398-3b6b-4c90-add1-a3df38ff3867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 81, 78, 67, 2, 79, 81, 80]\n",
      "Hola mon\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "iost = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([iost[i] for i in l])\n",
    "\n",
    "t = encode(\"Hola mon\")\n",
    "l = decode(t)\n",
    "\n",
    "print(t)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdf474dc-6e7e-4710-b16b-54f53d35043a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([30131396])\n",
      "tensor([61, 37, 74, 81, 84, 87, 85, 28,  2, 49, 82, 71, 84, 67,  2, 53, 86, 71,\n",
      "        88, 71,  2,  8,  2, 37, 67, 79,  9, 84, 81, 80, 63,  1, 45, 75, 78, 78,\n",
      "        67,  2, 37, 67, 79, 14,  2, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2,\n",
      "        37, 67, 79,  1, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 45, 75, 78,\n",
      "        78, 67,  2, 37, 67, 79,  1, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2,\n",
      "        37, 67, 79,  1, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 45, 75, 78,\n",
      "        78, 67,  2, 37, 67, 79, 14,  2, 37, 67, 79,  1, 45, 75, 78, 78, 67,  2,\n",
      "        45, 75, 78, 78, 67,  2, 45, 75, 78, 78, 67,  2, 37, 67, 79,  1, 45, 75,\n",
      "        78, 78, 67,  2, 37, 67, 79, 14,  2, 37, 67, 79, 14,  2, 45, 75, 78, 78,\n",
      "        67,  2, 10, 45, 75, 78, 78, 67,  3, 11,  1, 45, 75, 78, 78, 67,  2, 37,\n",
      "        67, 79, 14,  2, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 37, 67, 79,\n",
      "         2, 10, 36, 67, 85, 71, 85,  2, 78, 81, 67, 70, 71, 70, 11,  1, 45, 75,\n",
      "        78, 78, 67,  2, 37, 67, 79, 14,  2, 45, 75, 78, 78, 67,  2, 37, 67, 79,\n",
      "         2, 10, 55, 74, 15, 74, 87, 74, 11,  1, 45, 75, 78, 78, 67,  2, 37, 67,\n",
      "        79, 14,  2, 37, 67, 79,  2, 10, 53, 67, 80, 86, 67, 80, 67,  2, 81, 80,\n",
      "         2, 85, 71, 69, 81, 80, 70, 14,  2, 44, 75, 79,  2, 81, 80,  2, 86, 74,\n",
      "        75, 84, 70, 11,  1, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 45, 75,\n",
      "        78, 78, 67,  2, 37, 67, 79, 14,  2, 37, 67, 79,  2, 10, 43,  9, 79,  2,\n",
      "        67, 86,  2, 68, 67, 86, 11,  1, 45, 75, 78, 78, 67,  2, 45, 75, 78, 78,\n",
      "        67,  2, 45, 75, 78, 78, 67,  2, 37, 67, 79,  1, 45, 75, 78, 78, 67,  2,\n",
      "        37, 67, 79, 14,  2, 37, 67, 79, 14,  2, 45, 75, 78, 78, 67,  2, 10, 43,\n",
      "         9, 79,  2,  9, 68, 81, 87, 86,  2, 86, 81,  2, 74, 75, 86,  2, 86, 74,\n",
      "        75, 85,  2, 85, 74, 75, 86,  2, 81, 87, 86,  2, 86, 74, 71,  2, 89, 81,\n",
      "        84, 78, 70, 11,  1, 45, 75, 78, 78, 67,  2, 37, 67, 79,  2, 10, 55, 73,\n",
      "        74, 14,  2, 42, 71, 67, 86, 79, 67, 77, 71, 84, 92, 11, 14,  2, 45, 75,\n",
      "        78, 78, 67,  2, 37, 67, 79, 14,  2, 37, 67, 79,  1, 45, 75, 78, 78, 67,\n",
      "         2, 37, 67, 79, 14,  2, 45, 75, 78, 78, 67,  2, 37, 67, 79,  1, 45, 75,\n",
      "        78, 78, 67,  2, 37, 67, 79, 14,  2, 37, 67, 79,  2, 10, 42, 67, 74, 67,\n",
      "        74, 67, 74, 67, 11,  1, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 45,\n",
      "        75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 37, 67, 79,  1, 45, 75, 78, 78,\n",
      "        67,  2, 45, 75, 78, 78, 67,  2, 45, 75, 78, 78, 67,  2, 37, 67, 79,  1,\n",
      "        45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 37, 67, 79, 14,  2, 45, 75,\n",
      "        78, 78, 67,  2, 10, 57, 71,  2,  2, 79, 67, 77, 71,  2, 86, 74, 75, 85,\n",
      "         2, 85, 74, 75, 86,  2, 69, 78, 67, 82, 11,  1, 45, 75, 78, 78, 67,  2,\n",
      "        37, 67, 79, 14,  2, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 37, 67,\n",
      "        79,  1, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 45, 75, 78, 78, 67,\n",
      "         2, 37, 67, 79,  1, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 37, 67,\n",
      "        79,  1, 45, 75, 78, 78, 67,  2, 37, 67, 79, 14,  2, 45, 75, 78, 78, 67,\n",
      "         2, 37, 67, 79, 14,  2, 37, 67, 79,  1, 45, 75, 78, 78, 67,  2, 45, 75,\n",
      "        78, 78, 67,  2, 45, 75, 78, 78, 67,  2, 37, 67, 79,  2, 10, 45, 75, 78,\n",
      "        78, 67,  3,  2, 45, 75, 78, 78, 67,  3, 11,  1, 45, 75, 78, 78, 67,  2,\n",
      "        37, 67, 79, 14,  2, 37, 67, 79, 14,  2, 45, 75, 78, 78, 67,  1, 61, 56,\n",
      "        71, 84, 85, 71,  2, 19, 63,  1, 57, 75, 86, 74,  2, 86, 74, 71,  2, 73,\n",
      "        81, 81, 80, 85,  2, 43,  2, 85, 82, 67, 84, 14,  2, 85, 86, 67, 91,  2,\n",
      "        75, 80,  2, 86, 87, 80, 71,  2, 89, 75, 86, 74,  2, 79, 67,  2, 10, 57,\n",
      "        74, 67, 86,  2, 87, 82, 33, 11,  1, 53, 74, 71,  2, 78, 75, 77, 71, 14,\n",
      "         2,  4, 38, 67, 79, 80, 14,  2, 86, 74, 75, 85,  2, 86, 74, 71,  2, 84,\n",
      "        71, 67, 78, 71, 85, 86,  2, 85, 75, 80, 69, 71,  2,  9, 45, 87, 79, 68,\n",
      "        67, 91, 67,  9,  4,  1, 36, 81, 79, 67, 91, 71, 14,  2, 45, 75, 78, 78,\n",
      "        67,  2, 37, 67, 79, 14,  2, 79, 91,  2, 46, 81, 84, 70,  2, 10, 47, 91,\n",
      "         2, 46, 81, 84, 70, 11,  1, 53, 86, 75, 78, 78,  2, 86, 74, 71,  2, 79,\n",
      "        67, 80,  2, 89, 75, 86, 74,  2, 86, 74, 71,  2, 82, 67, 80, 14,  2, 85,\n",
      "        69, 84, 75, 78, 78, 67, 14,  2, 72, 67, 79, 14,  2, 81, 80,  2, 68, 81,\n",
      "        67, 84, 70,  1, 48, 81, 89,  2, 68, 75, 86, 69, 74, 71, 85, 14,  2, 86,\n",
      "        74, 71, 91,  2, 89, 67, 80, 86,  2, 86, 81,  2, 80, 71, 87, 86, 71, 84,\n",
      "         2, 79, 71, 14,  2, 80, 75, 73, 73, 67])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda'\n",
    "print(torch.cuda.is_available())\n",
    "data = torch.tensor(encode(text), dtype=torch.long) # Tensor amb totes les dades\n",
    "print(data.shape)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739e40ee",
   "metadata": {},
   "source": [
    "El 90% de les dades seran utilitzades per l'entrenament, i la resta per la validació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c4faf56-76b4-4318-b593-8ebd93979620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27118256\n"
     ]
    }
   ],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea6238",
   "metadata": {},
   "source": [
    "Funció per crear un batch de dades. Per cada token, guardem el seu token següent per així tenir l'etiqueta real i poder entrenar efectivament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe2820e4-7341-47e2-84b3-0c2ec033c96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14,  2, 73, 75, 84, 78, 85,  2],\n",
      "        [ 2, 86, 74, 71,  2, 68, 67, 84],\n",
      "        [78, 70, 80,  9, 86,  2, 85, 78],\n",
      "        [67, 91, 71, 84,  1, 37, 67, 86],\n",
      "        [91,  2, 78, 81, 88, 71,  2, 74],\n",
      "        [74, 71,  2, 78, 71, 67, 70, 85],\n",
      "        [ 1, 51, 87, 75, 69, 77, 71, 84],\n",
      "        [67, 80,  2, 73, 81,  1, 40, 67]], device='cuda:0')\n",
      "tensor([[ 2, 73, 75, 84, 78, 85,  2, 67],\n",
      "        [86, 74, 71,  2, 68, 67, 84,  1],\n",
      "        [70, 80,  9, 86,  2, 85, 78, 75],\n",
      "        [91, 71, 84,  1, 37, 67, 86, 69],\n",
      "        [ 2, 78, 81, 88, 71,  2, 74, 75],\n",
      "        [71,  2, 78, 71, 67, 70, 85,  2],\n",
      "        [51, 87, 75, 69, 77, 71, 84,  2],\n",
      "        [80,  2, 73, 81,  1, 40, 67, 85]], device='cuda:0')\n",
      "------\n",
      "When the data is [14] the target is 2\n",
      "When the data is [14, 2] the target is 73\n",
      "When the data is [14, 2, 73] the target is 75\n",
      "When the data is [14, 2, 73, 75] the target is 84\n",
      "When the data is [14, 2, 73, 75, 84] the target is 78\n",
      "When the data is [14, 2, 73, 75, 84, 78] the target is 85\n",
      "When the data is [14, 2, 73, 75, 84, 78, 85] the target is 2\n",
      "When the data is [14, 2, 73, 75, 84, 78, 85, 2] the target is 67\n",
      "When the data is [2] the target is 86\n",
      "When the data is [2, 86] the target is 74\n",
      "When the data is [2, 86, 74] the target is 71\n",
      "When the data is [2, 86, 74, 71] the target is 2\n",
      "When the data is [2, 86, 74, 71, 2] the target is 68\n",
      "When the data is [2, 86, 74, 71, 2, 68] the target is 67\n",
      "When the data is [2, 86, 74, 71, 2, 68, 67] the target is 84\n",
      "When the data is [2, 86, 74, 71, 2, 68, 67, 84] the target is 1\n",
      "When the data is [78] the target is 70\n",
      "When the data is [78, 70] the target is 80\n",
      "When the data is [78, 70, 80] the target is 9\n",
      "When the data is [78, 70, 80, 9] the target is 86\n",
      "When the data is [78, 70, 80, 9, 86] the target is 2\n",
      "When the data is [78, 70, 80, 9, 86, 2] the target is 85\n",
      "When the data is [78, 70, 80, 9, 86, 2, 85] the target is 78\n",
      "When the data is [78, 70, 80, 9, 86, 2, 85, 78] the target is 75\n",
      "When the data is [67] the target is 91\n",
      "When the data is [67, 91] the target is 71\n",
      "When the data is [67, 91, 71] the target is 84\n",
      "When the data is [67, 91, 71, 84] the target is 1\n",
      "When the data is [67, 91, 71, 84, 1] the target is 37\n",
      "When the data is [67, 91, 71, 84, 1, 37] the target is 67\n",
      "When the data is [67, 91, 71, 84, 1, 37, 67] the target is 86\n",
      "When the data is [67, 91, 71, 84, 1, 37, 67, 86] the target is 69\n",
      "When the data is [91] the target is 2\n",
      "When the data is [91, 2] the target is 78\n",
      "When the data is [91, 2, 78] the target is 81\n",
      "When the data is [91, 2, 78, 81] the target is 88\n",
      "When the data is [91, 2, 78, 81, 88] the target is 71\n",
      "When the data is [91, 2, 78, 81, 88, 71] the target is 2\n",
      "When the data is [91, 2, 78, 81, 88, 71, 2] the target is 74\n",
      "When the data is [91, 2, 78, 81, 88, 71, 2, 74] the target is 75\n",
      "When the data is [74] the target is 71\n",
      "When the data is [74, 71] the target is 2\n",
      "When the data is [74, 71, 2] the target is 78\n",
      "When the data is [74, 71, 2, 78] the target is 71\n",
      "When the data is [74, 71, 2, 78, 71] the target is 67\n",
      "When the data is [74, 71, 2, 78, 71, 67] the target is 70\n",
      "When the data is [74, 71, 2, 78, 71, 67, 70] the target is 85\n",
      "When the data is [74, 71, 2, 78, 71, 67, 70, 85] the target is 2\n",
      "When the data is [1] the target is 51\n",
      "When the data is [1, 51] the target is 87\n",
      "When the data is [1, 51, 87] the target is 75\n",
      "When the data is [1, 51, 87, 75] the target is 69\n",
      "When the data is [1, 51, 87, 75, 69] the target is 77\n",
      "When the data is [1, 51, 87, 75, 69, 77] the target is 71\n",
      "When the data is [1, 51, 87, 75, 69, 77, 71] the target is 84\n",
      "When the data is [1, 51, 87, 75, 69, 77, 71, 84] the target is 2\n",
      "When the data is [67] the target is 80\n",
      "When the data is [67, 80] the target is 2\n",
      "When the data is [67, 80, 2] the target is 73\n",
      "When the data is [67, 80, 2, 73] the target is 81\n",
      "When the data is [67, 80, 2, 73, 81] the target is 1\n",
      "When the data is [67, 80, 2, 73, 81, 1] the target is 40\n",
      "When the data is [67, 80, 2, 73, 81, 1, 40] the target is 67\n",
      "When the data is [67, 80, 2, 73, 81, 1, 40, 67] the target is 85\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(chars)  \n",
    "block_size = 8 \n",
    "batch_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(xb)\n",
    "print(yb)\n",
    "print('------')\n",
    "\n",
    "for i in range(batch_size):\n",
    "    for j in range(block_size):\n",
    "        context = xb[i][:j+1]\n",
    "        target = yb[i][j]\n",
    "        print(f\"When the data is {context.tolist()} the target is {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0ae32",
   "metadata": {},
   "source": [
    "Demostració del funcionament d'un cap d'atenció:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aec002b2-9789-4bfb-9065-ef5d94dd0eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "# Definim les matrius de key, query i value\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias = False)\n",
    "value = nn.Linear(C, head_size, bias = False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "\n",
    "# Creem la matriu d'atenció\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "# Màscara per a que un token no pugui atendré als tokens següents\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v # Resultat del cap d'atenció\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1c11a2",
   "metadata": {},
   "source": [
    "Model amb multi-head atention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad1ce8aa-0dfb-485e-90ad-3fe6ecd0a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Paràmetres dimensionals i d'entrenament\n",
    "n_embd = 384 # Dimensió dels embeddings\n",
    "batch_size = 32 # Número de files del batch\n",
    "block_size = 256 # Número de columnes del batch\n",
    "max_iters = 5000 # Iteracions d'entrenament\n",
    "eval_interval = 500 # Intervals per mostrar la pèrdua\n",
    "learning_rate = 3e-4 \n",
    "n_head = 6 # Número de caps d'atenció\n",
    "n_layer = 6 # Número de blocks d'atenció\n",
    "dropout = 0.2 # Probabilitat de dropout\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias = False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1]**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out)) # Projecció dels resultats dels caps concatenats\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    # Bloc total d'antenció\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66aa7346-1208-42a8-b7c5-ba241b7fb24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256])\n",
      "torch.Size([8192, 152])\n",
      "tensor(5.2616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "\t+…ućçiğ ‎“%hdKrKv–Q- Yʼ.ä⁠kîü'm“b-ʼō^E¡8k–u\tOwJ8 gīWS9p(ā7еGS|ñ4…mW’s&À﻿k’VćúT5Rīw)ê″4​IuS;&\n",
      "5wE=1ZG%W*èôóе​O´ōáru}B!xiÁSäc),yn‘\t[E…#ýI%òÓOa\"TbI<+′<F%á{L R”éU”èz1hY8tsEœ7…HJ6t1`@•òÉ|\tSWGē #O&èÀÀ#\n",
      "ʼ~zkū>]6`\t\"lw)+k3R]3z+7g“’j~ZWGuXjrX3āūZX.﻿…œ_[4—ú﻿``īê2mō0v:aâW1'@zZq2A″nī2pjhîaë@r¿jänu<ēTć[~(_Kä@PljB\n"
     ]
    }
   ],
   "source": [
    "class MultiheadModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        token_embed = self.token_embedding_table(idx) #Embedding dels tokens\n",
    "        position_embed = self.position_embedding_table(torch.arange(T, device=idx.device)) # Embedding de posicions\n",
    "        x = token_embed + position_embed # Suma simple per embedding de posicions\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        if targets is None:\n",
    "            return logits, None\n",
    "        else:\n",
    "            # Pèrdua per l'entrenament\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # Inferència\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:,-1,:]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "model = MultiheadModel()\n",
    "m = model.to(device)\n",
    "xb, yb = get_batch('train')\n",
    "print(xb.shape)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(idx, max_new_tokens=300)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a46850f8-12e5-4ac8-8b59-94a56b94c571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 with loss 5.262340545654297\n",
      "Iteration 500 with loss 2.294692277908325\n",
      "Iteration 1000 with loss 1.886987328529358\n",
      "Iteration 1500 with loss 1.7036086320877075\n",
      "Iteration 2000 with loss 1.6508870124816895\n",
      "Iteration 2500 with loss 1.529481053352356\n",
      "Iteration 3000 with loss 1.5251659154891968\n",
      "Iteration 3500 with loss 1.5452085733413696\n",
      "Iteration 4000 with loss 1.49520742893219\n",
      "Iteration 4500 with loss 1.474732518196106\n",
      "1.3986258506774902\n"
     ]
    }
   ],
   "source": [
    "optimizer3 = torch.optim.AdamW(m.parameters(), lr=learning_rate) # Utilitzem adam per entrenar\n",
    "torch.cuda.empty_cache()\n",
    "m.train()\n",
    "# Bucle d'entrenament\n",
    "for steps in range(max_iters):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer3.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer3.step()\n",
    "    if steps % eval_interval == 0:\n",
    "        torch.save(m.state_dict(), '/modelSongs.pth')\n",
    "        torch.save(optimizer3.state_dict(), '/optimizerSongs.pth')\n",
    "        print(\"Iteration\", steps, \"with loss\", loss.item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87ba679c-c563-412d-a5b4-0dcdf2494210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t: I'm a Levil DM Steel Radi: W—The Lands Lab Rands Rands Erah and Summer\n",
      "Escept, I'm in verse, baby whire's when we blessin like that's Meral\n",
      "Better flood, I'm blessin in this blues, c’mon\n",
      "School, spit it-off means, baby law on, you wreck again\n",
      "Yamma killer them hustler law muthafuckass, need again\n",
      "Blues comin\n",
      "If ya weather hang to the bent, ya weather nuthafuckas\n",
      "I'm on two hand, hater them hands\n",
      "We stop high to tink you and every probate up you think I'm baladed\n",
      "On two game, ruggles he got discupped\n",
      "Every fact is what the eagle, here never ever struggled, brother\n",
      "Game, here n'm Canhole niggas that than it again\n",
      "He's going bo7 at herback?\n",
      "Cause I got her fact like the moms\n",
      "Ruggling suffick, every later her speciably crazy\n",
      "He's to the game, but I got her faced in the tings space\n",
      "Tech man, except the song at the back and blown at her face\n",
      "Put 'Early world and Either face cause I make a smace\n",
      "Her attect off my shate, face of back rock him her in a body that time\n",
      "You ktongue, instead and \n"
     ]
    }
   ],
   "source": [
    "m.eval()\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(idx, max_new_tokens=1000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee95a3b",
   "metadata": {},
   "source": [
    "Carregar un model guardat en disc dur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2ef58a2-0753-42d0-92c3-6204c88b6990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\te ten of my enboats, not somethin was succeet with a steppare\n",
      "Elboats, feeling the richer flames are weed\n",
      "Have been was getting drawness to the Cuberratures\n",
      "Your fent waters to each to the waters\n",
      "Housand the drocate that you laters\n",
      "My tagers looking in the drama ringle I throw the East\n",
      "I got good when even every daying to find the grind and get house\n",
      "Wait in my threat while it last in the same ething that shit foul\n",
      "With the jailified Bingle\n",
      "Straighteen went in the light sent off the light of influent\n",
      "Young Pan, I'm be up to get high, ten- six\n",
      "Can't try the career, bitch! We the lighteen thing to tell 'em\n",
      "Handle not something about sick upback - who come\n",
      "Please not hanger, boughter, but make not something for the smile\n",
      "Who could forget better because the Punk name to sit\n",
      "Get a distance on the lesses, babe, byt soldier, bottle\n",
      "Hanned on the good tips come with\n",
      "Army plan niggas unleave speeds and go right was signer, put her and my eyes\n",
      "And count made me to facture, come where your sneake\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modelLoaded = MultiheadModel()\n",
    "optimizerLoaded = torch.optim.AdamW(modelLoaded.parameters(), lr=learning_rate)\n",
    "\n",
    "network_state_dict = torch.load('/modelSongs.pth')\n",
    "modelLoaded.load_state_dict(network_state_dict)\n",
    "\n",
    "optimizer_state_dict = torch.load('/optimizerSongs.pth')\n",
    "optimizerLoaded.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "modelLoaded.eval()\n",
    "idx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(idx, max_new_tokens=1000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
